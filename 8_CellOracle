#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# 0. Import

import os
import sys

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scanpy as sc
import seaborn as sns
import anndata as ad
from scipy.sparse import csr_matrix
import scanpy as sc


# In[ ]:


import celloracle as co
co.__version__


# In[ ]:


# visualization settings
get_ipython().run_line_magic('config', "InlineBackend.figure_format = 'retina'")
get_ipython().run_line_magic('matplotlib', 'inline')

plt.rcParams['figure.figsize'] = [6, 4.5]
plt.rcParams["savefig.dpi"] = 300


# In[ ]:


save_folder = "figures"
os.makedirs(save_folder, exist_ok=True)


# In[6]:


A_D=ad.read_h5ad('Justine_all_SC_no68_adata.h5ad')
A_D


# In[26]:


A_D_all=ad.read_h5ad('Justine_all_SC_no6810_all_adata.h5ad')
A_D_all


# In[5]:


# Load TF info which was made from mouse cell atlas dataset.
base_GRN = co.data.load_mouse_scATAC_atlas_base_GRN()

# Check data
base_GRN.head()


# In[6]:


# Instantiate Oracle object
oracle = co.Oracle()


# In[41]:


# Check data in anndata
print("Metadata columns :", list(A_D.obs.columns))
print("Dimensional reduction: ", list(A_D.obsm.keys()))


# In[11]:


# keep raw count data before log transformation
A_D.raw = A_D
A_D.layers["raw_count"] = A_D.raw.X.copy()

# Instantiate Oracle object.
oracle.import_anndata_as_raw_count(adata=A_D,
                                   cluster_column_name="seurat_clusters",
                                   embedding_name="UMAP")


# In[21]:


# keep raw cont data before log transformation
#A_D_all.raw = A_D_all
#A_D_all.layers["raw_count"] = A_D_all.raw.X.copy()

# Instantiate Oracle object.
#oracle.import_anndata_as_raw_count(adata=A_D_all,
                                   #cluster_column_name="seurat_clusters",
                                   #embedding_name="UMAP")


# In[12]:


# You can load TF info dataframe with the following code.
oracle.import_TF_data(TF_info_matrix=base_GRN)


# In[44]:


# Perform PCA
oracle.perform_PCA()

# Select important PCs
plt.plot(np.cumsum(oracle.pca.explained_variance_ratio_)[:100])
n_comps = np.where(np.diff(np.diff(np.cumsum(oracle.pca.explained_variance_ratio_))>0.002))[0][0]
plt.axvline(n_comps, c="k")
plt.show()
print(n_comps)
n_comps = min(n_comps, 50)


# In[45]:


n_cell = oracle.adata.shape[0]
print(f"cell number is :{n_cell}")


# In[46]:


k = int(0.025*n_cell)
print(f"Auto-selected k is :{k}")


# In[19]:


oracle.knn_imputation(n_pca_dims=n_comps, k=k, balanced=True, b_sight=k*8,
                      b_maxl=k*4, n_jobs=4)


# In[20]:


# Save oracle object.
oracle.to_hdf5("Justine_all_SC_no68.celloracle.oracle")


# In[5]:


# Save oracle object.
#oracle.to_hdf5("Justine_all_SC_no6810_all.celloracle.oracle")


# In[ ]:


# Load file.
oracle = co.load_hdf5("Justine_all_SC_no68.celloracle.oracle")
oracle


# In[8]:


# Load file.
#oracle = co.load_hdf5("Justine_all_SC_no8.celloracle.oracle")
#oracle


# In[ ]:


# Check clustering data
#sc.pl.draw_graph(oracle.adata, color="seurat_clusters")


# In[23]:


get_ipython().run_cell_magic('time', '', '# Calculate GRN for each population in "louvain_annot" clustering unit.\n# This step may take some time.(~8 hours)\nlinks = oracle.get_links(cluster_name_for_GRN_unit="seurat_clusters", alpha=10,\n                         verbose_level=10, n_jobs=-1)\n')


# In[24]:


links.filter_links(p=0.001, weight="coef_abs", threshold_number=2000)


# In[25]:


plt.rcParams["figure.figsize"] = [9, 4.5]


# In[26]:


links.plot_degree_distributions(plot_model=True, 
                                               #save=f"{save_folder}/degree_distribution/",
                                               )


# In[24]:


# Calculate network scores. It takes several minutes.
links.get_score(n_jobs=8)


# In[27]:


# Calculate network scores.
links.get_network_score()


# In[26]:


links.merged_score.head()


# In[13]:


# Save Links object.
links.to_hdf5(file_path="no68_links.celloracle.links")


# In[9]:


# You can load files with the following command.
links = co.load_hdf5(file_path="no68_links.celloracle.links")


# In[10]:


# Check cluster name
links.cluster


# In[27]:


links.filter_links()
oracle.get_cluster_specific_TFdict_from_Links(links_object=links)
oracle.fit_GRN_for_simulation(alpha=10,
                              use_cluster_specific_TFdict=True)


# In[28]:


goi = "Sox10"
sc.pl.draw_graph(oracle.adata, color=[goi, oracle.cluster_column_name],
                 layer="imputed_count", use_raw=False, cmap="viridis")


# In[29]:


# Compare GRN score between two clusters
links.plot_score_comparison_2D(value="eigenvector_centrality",
                               cluster1="6", cluster2="8",
                               percentile=98,
                               save=f"{save_folder}/score_comparison")


# In[18]:


# Compare GRN score between two clusters
links.plot_score_comparison_2D(value="eigenvector_centrality",
                               cluster1="4", cluster2="6",
                               percentile=98,
                               save=f"{save_folder}/score_comparison")


# In[19]:


# Enter perturbation conditions: KO
oracle.simulate_shift(perturb_condition={goi: 0.0},
                      n_propagation=3)


# In[30]:


# Enter perturbation conditions: overexpressino
oracle.simulate_shift(perturb_condition={goi: 1},
                      n_propagation=3)


# In[ ]:


# Get transition probability
oracle.estimate_transition_prob(n_neighbors=200,
                                knn_random=True,
                                sampled_fraction=1)

# Calculate embedding
oracle.calculate_embedding_shift(sigma_corr=0.05)


# In[ ]:


fig, ax = plt.subplots(1, 2,  figsize=[13, 6])

scale = 10
# Show quiver plot
oracle.plot_quiver(scale=scale, ax=ax[0])
ax[0].set_title(f"Simulated cell identity shift vector: {goi} KO")

# Show quiver plot that was calculated with randomized graph.
oracle.plot_quiver_random(scale=scale, ax=ax[1])
ax[1].set_title(f"Randomized simulation vector")

plt.show()


# In[16]:


# n_grid = 40 is a good starting value.
n_grid = 40
oracle.calculate_p_mass(smooth=0.8, n_grid=n_grid, n_neighbors=200)


# In[17]:


# Search for best min_mass.
oracle.suggest_mass_thresholds(n_suggestion=12)


# In[18]:


min_mass = 30
oracle.calculate_mass_filter(min_mass=min_mass, plot=True)


# In[19]:


fig, ax = plt.subplots(1, 2,  figsize=[13, 6])

scale_simulation = 10
# Show quiver plot
oracle.plot_simulation_flow_on_grid(scale=scale_simulation, ax=ax[0])
ax[0].set_title(f"Simulated cell identity shift vector: {goi} KO")

# Show quiver plot that was calculated with randomized graph.
oracle.plot_simulation_flow_random_on_grid(scale=scale_simulation, ax=ax[1])
ax[1].set_title(f"Randomized simulation vector")

plt.show()


# In[20]:


# Plot vector field with cell cluster
fig, ax = plt.subplots(figsize=[8, 8])

oracle.plot_cluster_whole(ax=ax, s=10)
oracle.plot_simulation_flow_on_grid(scale=scale_simulation, ax=ax, show_background=False)


# In[21]:


# Visualize pseudotime
fig, ax = plt.subplots(figsize=[6,6])

sc.pl.embedding(adata=oracle.adata, basis=oracle.embedding_name, ax=ax, cmap="rainbow",
                color=["Pseudotime"])


# In[22]:


from celloracle.applications import Gradient_calculator

# Instantiate Gradient calculator object
gradient = Gradient_calculator(oracle_object=oracle, pseudotime_key="Pseudotime")


# In[23]:


gradient.calculate_p_mass(smooth=0.8, n_grid=n_grid, n_neighbors=200)
gradient.calculate_mass_filter(min_mass=min_mass, plot=True)


# In[24]:


gradient.transfer_data_into_grid(args={"method": "polynomial", "n_poly":3}, plot=True)


# In[25]:


# Calculate graddient
gradient.calculate_gradient()

# Show results
scale_dev = 40
gradient.visualize_results(scale=scale_dev, s=5)


# In[26]:


# Visualize results
fig, ax = plt.subplots(figsize=[6, 6])
gradient.plot_dev_flow_on_grid(scale=scale_dev, ax=ax)


# In[29]:


# Save gradient object 
gradient.to_hdf5("Justine_S_no68.celloracle.gradient")


# In[30]:


from celloracle.applications import Oracle_development_module

# Make Oracle_development_module to compare two vector field
dev = Oracle_development_module()

# Load development flow
dev.load_differentiation_reference_data(gradient_object=gradient)

# Load simulation result
dev.load_perturb_simulation_data(oracle_object=oracle)


# Calculate inner produc scores
dev.calculate_inner_product()
dev.calculate_digitized_ip(n_bins=10)


# In[31]:


# Show perturbation scores
vm = 0.02

fig, ax = plt.subplots(1, 2, figsize=[12, 6])
dev.plot_inner_product_on_grid(vm=0.02, s=50, ax=ax[0])
ax[0].set_title(f"PS")

dev.plot_inner_product_random_on_grid(vm=vm, s=50, ax=ax[1])
ax[1].set_title(f"PS calculated with Randomized simulation vector")
plt.show()


# In[32]:


# Show perturbation scores with perturbation simulation vector field
fig, ax = plt.subplots(figsize=[6, 6])
dev.plot_inner_product_on_grid(vm=vm, s=50, ax=ax)
dev.plot_simulation_flow_on_grid(scale=scale_simulation, show_background=False, ax=ax)


# In[33]:


# Let's visualize the results 
dev.visualize_development_module_layout_0(s=5, 
                                          scale_for_simulation=scale_simulation,
                                          s_grid=50,
                                          scale_for_pseudotime=scale_dev, 
                                          vm=vm)


# In[ ]:
